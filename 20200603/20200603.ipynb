{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(64, activation = 'relu', input_shape=(4,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                704       \n",
      "=================================================================\n",
      "Total params: 1,674\n",
      "Trainable params: 1,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.8231 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 954us/step - loss: 7.4956 - acc: 0.0067\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 902us/step - loss: 7.2301 - acc: 0.2200\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 925us/step - loss: 6.8799 - acc: 0.3333\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 821us/step - loss: 6.4101 - acc: 0.3333\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 899us/step - loss: 5.9298 - acc: 0.3333\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 872us/step - loss: 5.5292 - acc: 0.3333\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 783us/step - loss: 5.2735 - acc: 0.3333\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 828us/step - loss: 5.1854 - acc: 0.3333\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 762us/step - loss: 5.1041 - acc: 0.3533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbe321c6a50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data.data, data.target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 554 kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow-hub) (1.18.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow-hub) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow-hub) (3.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow-hub) (46.0.0.post20200309)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-3.1.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 570 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=18.1.0 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (19.3.0)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 25.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: absl-py in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: numpy in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.18.1)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.22.1-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: termcolor in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (3.12.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (2.22.0)\n",
      "Requirement already satisfied: future in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: wrapt in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.11.2)\n",
      "Requirement already satisfied: tqdm in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (4.42.1)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting googleapis-common-protos\n",
      "  Downloading googleapis-common-protos-1.51.0.tar.gz (35 kB)\n",
      "Requirement already satisfied: setuptools in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow_datasets) (46.0.0.post20200309)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sangkim/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
      "Building wheels for collected packages: dill, promise, googleapis-common-protos\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=b8d09beb841a321e5079e7394c0f8bc8f899cd4f7725091535cad91f1a00e8a2\n",
      "  Stored in directory: /Users/sangkim/Library/Caches/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=6b0b1bab3d8b2278d7a2375f3b8c77eabff314a48c0453de90db6a65bcc43a1e\n",
      "  Stored in directory: /Users/sangkim/Library/Caches/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "  Building wheel for googleapis-common-protos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.51.0-py3-none-any.whl size=77592 sha256=a6828e7aae32501bd2dc59af72bc31b6f28986c994bd1acd2eda28a21b8038ef\n",
      "  Stored in directory: /Users/sangkim/Library/Caches/pip/wheels/4c/a1/71/5e427276ceeff277fd76878d1b19fbf4587a2845015d86864b\n",
      "Successfully built dill promise googleapis-common-protos\n",
      "Installing collected packages: dill, googleapis-common-protos, tensorflow-metadata, promise, tensorflow-datasets\n",
      "Successfully installed dill-0.3.1.1 googleapis-common-protos-1.51.0 promise-2.3 tensorflow-datasets-3.1.0 tensorflow-metadata-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GenerateMode',\n",
       " 'ReadConfig',\n",
       " 'Split',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'absolute_import',\n",
       " 'as_numpy',\n",
       " 'audio',\n",
       " 'builder',\n",
       " 'builder_cls',\n",
       " 'core',\n",
       " 'decode',\n",
       " 'disable_progress_bar',\n",
       " 'division',\n",
       " 'download',\n",
       " 'features',\n",
       " 'image',\n",
       " 'image_classification',\n",
       " 'is_dataset_on_gcs',\n",
       " 'list_builders',\n",
       " 'load',\n",
       " 'object_detection',\n",
       " 'print_function',\n",
       " 'proto',\n",
       " 'public_api',\n",
       " 'show_examples',\n",
       " 'structured',\n",
       " 'summarization',\n",
       " 'testing',\n",
       " 'text',\n",
       " 'tf_compat',\n",
       " 'translate',\n",
       " 'units',\n",
       " 'version',\n",
       " 'video',\n",
       " 'visualization']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tfds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset arc/2019-12-06/1.0.0 (download: 465.07 KiB, generated: Unknown size, total: 465.07 KiB) to /Users/sangkim/tensorflow_datasets/arc/2019-12-06/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29823ca0422f4c5e814c9380316530ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40c0bbd159d49a1a9241f38f4d840a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ec5c2f82884a08b820b185f313ef59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangkim/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "/Users/sangkim/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'codeload.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Shuffling and writing examples to /Users/sangkim/tensorflow_datasets/arc/2019-12-06/1.0.0.incomplete9RGE7P/arc-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6d69e5f16f40ec9feb75a9996f89ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Shuffling and writing examples to /Users/sangkim/tensorflow_datasets/arc/2019-12-06/1.0.0.incomplete9RGE7P/arc-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c005e2ae4ca48b0b97de41be9b78708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset arc downloaded and prepared to /Users/sangkim/tensorflow_datasets/arc/2019-12-06/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test': <PrefetchDataset shapes: {task_id: (), test: {input: (None, None, None), output: (None, None, None)}, train: {input: (None, None, None), output: (None, None, None)}}, types: {task_id: tf.string, test: {input: tf.int32, output: tf.int32}, train: {input: tf.int32, output: tf.int32}}>,\n",
       " 'train': <PrefetchDataset shapes: {task_id: (), test: {input: (None, None, None), output: (None, None, None)}, train: {input: (None, None, None), output: (None, None, None)}}, types: {task_id: tf.string, test: {input: tf.int32, output: tf.int32}, train: {input: tf.int32, output: tf.int32}}>}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.load('arc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/sangkim/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
      "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a1dd7a7d034f98b7fbe16d8bb5a335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /Users/sangkim/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = tfds.load('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfds.load('mnist', split=(tfds.Split.TRAIN, tfds.Split.TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
