{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tensorflow\" data-toc-modified-id=\"Tensorflow-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tensorflow</a></span><ul class=\"toc-item\"><li><span><a href=\"#iris-dataset\" data-toc-modified-id=\"iris-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>iris dataset</a></span></li></ul></li><li><span><a href=\"#Tensorflow-hub\" data-toc-modified-id=\"Tensorflow-hub-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tensorflow-hub</a></span></li><li><span><a href=\"#Tensorflow-datasets\" data-toc-modified-id=\"Tensorflow-datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Tensorflow-datasets</a></span></li><li><span><a href=\"#맛보기\" data-toc-modified-id=\"맛보기-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>맛보기</a></span><ul class=\"toc-item\"><li><span><a href=\"#tfds\" data-toc-modified-id=\"tfds-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>tfds</a></span></li><li><span><a href=\"#hub\" data-toc-modified-id=\"hub-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>hub</a></span></li></ul></li><li><span><a href=\"#딥러닝-Regression\" data-toc-modified-id=\"딥러닝-Regression-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>딥러닝 Regression</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [AI 오픈 이노베이션] 기본 저녁반<a class=\"tocSkip\">\n",
    "GitHub link: [https://github.com/realblack0/8th_ai_lecture_fundamental](https://github.com/realblack0/8th_ai_lecture_fundamental)  \n",
    "E-Mail: realblack0@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 레이어에는 input_shape을 써야한다.\n",
    "# iris의 feature는 4개 이므로 input_shape은 (4,)이다. (feature = column)\n",
    "# input_shape은 tuple이어야한다. \n",
    "# (4,)는 값이 1개인 튜플\n",
    "model.add(tf.keras.layers.Dense(64, input_shape=(4,), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax는 중간 레이어에는 쓸 수 없고, 마지막 레이어에서만 사용 가능하다.\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 515\n",
      "Trainable params: 515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_crossentropy는 classification용 loss function이다.\n",
    "# target이 OneHotEncoding 되어 있지 않은 경우 sparse_를 붙인다.\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 1s 6ms/sample - loss: 1.3697 - acc: 0.3333\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.1521 - acc: 0.3333\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.0683 - acc: 0.4933\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9874 - acc: 0.5467\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9079 - acc: 0.8133\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8375 - acc: 0.6867\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7782 - acc: 0.6667\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7315 - acc: 0.6867\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6937 - acc: 0.7733\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6595 - acc: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b623bd710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data.data, data.target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1,\n",
       "       2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\jinhyo\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-hub) (1.18.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\jinhyo\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-hub) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow-hub) (3.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from protobuf>=3.4.0->tensorflow-hub) (46.4.0.post20200518)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasnfer learning을 위한 라이브러리이다.\n",
    "# https://www.tensorflow.org/hub?hl=ko\n",
    "import tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorflow_hub의사용방법은 [텐서플로우 공식 튜토리얼:IMDB 영화리뷰 분류](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub?hl=ko)를 참고하세요.\n",
    "- IMDB 영화리뷰 분류는 자연어처리 문제이므로 우리가 배우지 않은 내용이 조금 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\jinhyo\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.15.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jinhyo\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.18.1)\n",
      "Requirement already satisfied: dill in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.3.1.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.7.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.23.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.46.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.12.1)\n",
      "Requirement already satisfied: future in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.9.1)\n",
      "Requirement already satisfied: promise in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jinhyo\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow_datasets) (46.4.0.post20200518)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 자체에서 연습용 데이터를 제공한다.\n",
    "# https://www.tensorflow.org/datasets?hl=ko\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 실행하기 전에 중간에 값 확인할 수 있다.\n",
    "# tensorflow 버전 1에서는 중간에 값 확인할 수 없었다.\n",
    "# 버전 2부터는 기본설정이 True이다.\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용가능 자원 확인\n",
    "# GPU가 사용가능하면 GPU가 목록에 있을 것이다.\n",
    "# GPU가 없으면 사용할 수 없다.\n",
    "# PC에 GPU가 있는데 안 보인다면 nvidia GPU인지 확인한다.\n",
    "tf.config.experimental.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용가능한 물리 자원 확인\n",
    "# 가상자원에도 할당할 수 있기 때문에 필요하다.\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 맛보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 수업은 [Tensorflow 공식문서 튜토리얼](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub?hl=ko)을 참고하여 진행하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
       " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy(CPU) > tensor(GPU)\n",
    "# tensorflow는 numpy를 기반으로 만들어졌기 떄문에 호환이 된다.\n",
    "# 데이터를 numpy array로 불러와도 된다.\n",
    "# numpy array를 tensorflow에서 사용할 수 있지만, 내부적으로 tensor로 변환 과정을 거친다.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow_datasets는 데이터를 tensor로 불러온다.\n",
    "# 애초에 데이터를 tensor로 불러오면\n",
    "# CPU에서 GPU로 변환하는 시간 절약할 수 있고,\n",
    "# GPU로 처리하기 때문에 더 빨리 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow ver.2부터 전처리 기능을 추가했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GenerateMode',\n",
       " 'ReadConfig',\n",
       " 'Split',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'absolute_import',\n",
       " 'as_numpy',\n",
       " 'audio',\n",
       " 'builder',\n",
       " 'core',\n",
       " 'decode',\n",
       " 'disable_progress_bar',\n",
       " 'division',\n",
       " 'download',\n",
       " 'features',\n",
       " 'file_adapter',\n",
       " 'image',\n",
       " 'is_dataset_on_gcs',\n",
       " 'list_builders',\n",
       " 'load',\n",
       " 'object_detection',\n",
       " 'percent',\n",
       " 'print_function',\n",
       " 'public_api',\n",
       " 'show_examples',\n",
       " 'structured',\n",
       " 'summarization',\n",
       " 'testing',\n",
       " 'text',\n",
       " 'tf_compat',\n",
       " 'translate',\n",
       " 'units',\n",
       " 'version',\n",
       " 'video']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tfds) # 처음보면 dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'amazon_us_reviews',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'cos_e',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'downsampled_imagenet',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'dummy_dataset_shared_generator',\n",
       " 'dummy_mnist',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'gap',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'groove',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'i_naturalist2017',\n",
       " 'image_label_folder',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet_resized',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_rationales',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'omniglot',\n",
       " 'open_images_v4',\n",
       " 'opinosis',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'pet_finder',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'qa4mre',\n",
       " 'quickdraw_bitmap',\n",
       " 'reddit_tifu',\n",
       " 'resisc45',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'shapes3d',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trivia_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vgg_face2',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'wider_face',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'xnli',\n",
       " 'xsum',\n",
       " 'yelp_polarity_reviews']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용할 수 있는 데이터셋 이름 목록\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to C:\\Users\\JINHYO\\tensorflow_datasets\\mnist\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0603 20:44:24.143509 18544 dataset_builder.py:334] Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c82958649946e48ea6b3854032711b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\JINHYO\\tensorflow_datasets\\mnist\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 위의 데이터 이름 목록에 있는 데이터를 load한다.\n",
    "# return이 dictionary이다.\n",
    "data = tfds.load('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary에서 train 데이터만 뽑을 수 있다.\n",
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 옵션으로 train 데이터만 로드할 수 있다.\n",
    "data_s = tfds.load('mnist', split=tfds.Split.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       " <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 셋과 test 셋을 split 옵션을 이용해서 불러올 수 있다.\n",
    "tfds.load('mnist', split=(tfds.Split.TRAIN, tfds.Split.TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking\n",
    "train_data, test_data = tfds.load('mnist', split=(tfds.Split.TRAIN, tfds.Split.TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       " <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as_supervised=True는 데이터와 정답을 tuple 형태로 반환한다.\n",
    "tfds.load('mnist', split=(tfds.Split.TRAIN, tfds.Split.TEST), as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       " <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as_supervised=False는 데이터와 정답을 dictionary 형태로 반환한다.\n",
    "tfds.load('mnist', split=(tfds.Split.TRAIN, tfds.Split.TEST), as_supervised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_as_variant_tensor',\n",
       " '_checkpoint_dependencies',\n",
       " '_component_metadata',\n",
       " '_consumers',\n",
       " '_dataset',\n",
       " '_deferred_dependencies',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_from_components',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_graph_attr',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_inputs',\n",
       " '_is_graph_tensor',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_make_initializable_iterator',\n",
       " '_make_one_shot_iterator',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_to_components',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " '_variant_tensor_attr',\n",
       " '_variant_tracker',\n",
       " 'apply',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'filter_with_legacy_function',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_sparse_tensor_slices',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'make_initializable_iterator',\n",
       " 'make_one_shot_iterator',\n",
       " 'map',\n",
       " 'map_with_legacy_function',\n",
       " 'options',\n",
       " 'output_classes',\n",
       " 'output_shapes',\n",
       " 'output_types',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator라는 이름이 보인다. -> for문에 넣을 수 있다.\n",
    "dir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <tf.Tensor: id=4104, shape=(28, 28, 1), dtype=uint8, numpy=\n",
      "array([[[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 84],\n",
      "        [254],\n",
      "        [101],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [174],\n",
      "        [253],\n",
      "        [119],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 31],\n",
      "        [247],\n",
      "        [202],\n",
      "        [ 29],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  1],\n",
      "        [  1],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [141],\n",
      "        [253],\n",
      "        [168],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 66],\n",
      "        [208],\n",
      "        [ 56],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [186],\n",
      "        [253],\n",
      "        [120],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 57],\n",
      "        [253],\n",
      "        [119],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 28],\n",
      "        [249],\n",
      "        [240],\n",
      "        [ 25],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 34],\n",
      "        [253],\n",
      "        [119],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [109],\n",
      "        [254],\n",
      "        [197],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 53],\n",
      "        [253],\n",
      "        [119],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [135],\n",
      "        [254],\n",
      "        [133],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [133],\n",
      "        [254],\n",
      "        [119],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 27],\n",
      "        [240],\n",
      "        [255],\n",
      "        [ 35],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  7],\n",
      "        [235],\n",
      "        [253],\n",
      "        [208],\n",
      "        [151],\n",
      "        [169],\n",
      "        [215],\n",
      "        [253],\n",
      "        [206],\n",
      "        [  2],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 97],\n",
      "        [253],\n",
      "        [253],\n",
      "        [253],\n",
      "        [254],\n",
      "        [253],\n",
      "        [253],\n",
      "        [253],\n",
      "        [ 86],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [150],\n",
      "        [244],\n",
      "        [145],\n",
      "        [119],\n",
      "        [101],\n",
      "        [ 82],\n",
      "        [253],\n",
      "        [253],\n",
      "        [ 14],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 84],\n",
      "        [254],\n",
      "        [172],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [174],\n",
      "        [253],\n",
      "        [119],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [237],\n",
      "        [252],\n",
      "        [ 56],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [ 50],\n",
      "        [241],\n",
      "        [182],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [187],\n",
      "        [254],\n",
      "        [249],\n",
      "        [105],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [186],\n",
      "        [253],\n",
      "        [206],\n",
      "        [ 21],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [227],\n",
      "        [242],\n",
      "        [ 32],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [236],\n",
      "        [219],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]],\n",
      "\n",
      "       [[  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0],\n",
      "        [  0]]], dtype=uint8)>, 'label': <tf.Tensor: id=4105, shape=(), dtype=int64, numpy=4>}\n"
     ]
    }
   ],
   "source": [
    "# for문으로 데이터를 확인해본다.\n",
    "for i in train_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for에 들어갈 수 있으면 iterator로 만들 수 있다. iter는 iterator로 만든다.\n",
    "# batch는 묶음이다.\n",
    "# batch(10)은 데이터를 10개씩 묶어서 뽑아온다.\n",
    "x = iter(train_data.batch(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <tf.Tensor: id=4124, shape=(10, 28, 28, 1), dtype=uint8, numpy=\n",
       " array([[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]], dtype=uint8)>,\n",
       " 'label': <tf.Tensor: id=4125, shape=(10,), dtype=int64, numpy=array([4, 1, 0, 7, 8, 1, 2, 7, 1, 6], dtype=int64)>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterator는 next로 다음 값 뽑아온다.\n",
    "next(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0603 22:12:49.705152 18544 dataset_builder.py:673] Found a different version 0.1.0 of dataset imdb_reviews in data_dir C:\\Users\\JINHYO\\tensorflow_datasets. Using currently defined version 1.0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to C:\\Users\\JINHYO\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09628c14ff244c40a7998453077dcb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb251b560de24aceb855d9538be0a83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\JINHYO\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete4QP5CL\\imdb_reviews-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5c9ed1aa9c4c4ca76d09c84c601ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\JINHYO\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete4QP5CL\\imdb_reviews-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0fd3bdf3464b70aee8277df75f8821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\JINHYO\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete4QP5CL\\imdb_reviews-unsupervised.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5601a2dc78416ba5f15490393850e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\JINHYO\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-541bb0460665>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"imdb_reviews\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_validation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     as_supervised=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    316\u001b[0m   \u001b[0mas_dataset_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"read_config\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m   \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mas_dataset_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[1;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised, in_memory)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0min_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     )\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_single_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[1;32m--> 153\u001b[1;33m                 for v in data_struct]\n\u001b[0m\u001b[0;32m    154\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[1;32m--> 153\u001b[1;33m                 for v in data_struct]\n\u001b[0m\u001b[0;32m    154\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[1;32m--> 153\u001b[1;33m                 for v in data_struct]\n\u001b[0m\u001b[0;32m    154\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[1;32m--> 153\u001b[1;33m                 for v in data_struct]\n\u001b[0m\u001b[0;32m    154\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m   \u001b[1;31m# Singleton\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[1;34m(self, split, shuffle_files, batch_size, decoders, read_config, as_supervised, in_memory)\u001b[0m\n\u001b[0;32m    539\u001b[0m           \u001b[0mshuffle_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m           \u001b[0mdecoders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m           \u001b[0mread_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m       )\n\u001b[0;32m    543\u001b[0m       \u001b[1;31m# Auto-cache small datasets which are small enough to fit in memory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[1;34m(self, split, decoders, read_config, shuffle_files)\u001b[0m\n\u001b[0;32m    947\u001b[0m           \u001b[0msplit_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m           \u001b[0mread_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m           \u001b[0mshuffle_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       )\n\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, name, instructions, split_infos, read_config, shuffle_files)\u001b[0m\n\u001b[0;32m    288\u001b[0m       )\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_read_instruction_to_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m   def read_files(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36m_read_instruction_to_ds\u001b[1;34m(instruction)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \"\"\"\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_instruction_to_ds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m       \u001b[0mfile_instructions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_file_instructions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m       \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_instructions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_instructions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[1;34m(name, split_infos, instruction)\u001b[0m\n\u001b[0;32m    119\u001b[0m   }\n\u001b[0;32m    120\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0minstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m   \u001b[1;31m# Create the absolute instruction (per split)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[0mabsolute_instructions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36mfrom_spec\u001b[1;34m(cls, spec)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msubs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No instructions could be built out of %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m     \u001b[0minstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_str_to_relative_instruction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m     return sum([_str_to_relative_instruction(sub) for sub in subs[1:]],\n\u001b[0;32m    518\u001b[0m                instruction)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36m_str_to_relative_instruction\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    354\u001b[0m   \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_SUB_SPEC_RE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized instruction format: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m   \u001b[0munit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'from_pct'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'to_pct'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'abs'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m   return ReadInstruction(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])"
     ]
    }
   ],
   "source": [
    "# 훈련 세트를 6대 4로 나눕니다.\n",
    "# 결국 훈련에 15,000개 샘플, 검증에 10,000개 샘플, 테스트에 25,000개 샘플을 사용하게 됩니다.\n",
    "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
    "\n",
    "(train_data, validation_data), test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=(train_validation_split, tfds.Split.TEST),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], # 자연어처리는 input 크기가 일정하지 않으므로 빈 리스트\n",
    "                           dtype=tf.string, \n",
    "                           trainable=True) # trainable은 학습이 가능하게 가져올 지를 정한다.\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "# 마지막 레이어에 activation이 없으면 regression 문제이다.\n",
    "# 모든 regression 문제는 부등식으로 만들어서 classification 문제로 바꿀 수 있다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 수업은 [Tensorflow 튜토리얼](https://www.tensorflow.org/tutorials/keras/regression?hl=ko)을 참고하여 진행되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow도 numpy 데이터 호환되므로, sklearn 연습데이터를 쓸 수 있다.\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape = (13,)\n",
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units를 정하는 원칙 -> 없다! (경험적으로)\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(13,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 레이어에 activation이 없으면 regression이다.\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 481\n",
      "Trainable params: 481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델이 잘 만들어졌는지 확인하기 위해서 summary를 꼭 해본다.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression 문제로 접근하면, loss function을 regression 용으로 바꿔야 한다.\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
